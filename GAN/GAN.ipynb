{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('AGG')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\") \n",
    "\n",
    "# display plots in this notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use fully connected layer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "Z_dim = 100\n",
    "h_dim = 128\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, X_dim], name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('D') as scope:\n",
    "    D_W1 = tf.get_variable('W1', shape=[X_dim, h_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    D_b1 = tf.get_variable('b1', shape=[h_dim], initializer=tf.zeros_initializer())\n",
    "    D_W2 = tf.get_variable('W2', shape=[h_dim, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    D_b2 = tf.get_variable('b2', shape=[1], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_D = [D_W1, D_b1, D_W2, D_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim], name='Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('G') as scope:\n",
    "    G_W1 = tf.get_variable('W1', shape=[Z_dim, h_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    G_b1 = tf.get_variable('b1', shape=[h_dim], initializer=tf.zeros_initializer())\n",
    "    G_W2 = tf.get_variable('W2', shape=[h_dim, X_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    G_b2 = tf.get_variable('b2', shape=[X_dim], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_G = [G_W1, G_b1, G_W2, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1, 1, size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_logit = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_logit)\n",
    "    \n",
    "    return G_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "    \n",
    "    return D_prob, D_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_sample = generator(Z)\n",
    "D_prob_real, D_logit_real = discriminator(X)\n",
    "D_prob_fake, D_logit_fake = discriminator(G_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
    "\n",
    "D_loss = D_loss_real + D_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=var_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=var_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 1.828\n",
      "G loss: 1.244\n",
      "Iter: 1000\n",
      "D loss: 0.05881\n",
      "G loss: 4.585\n",
      "Iter: 2000\n",
      "D loss: 0.09512\n",
      "G loss: 4.38\n",
      "Iter: 3000\n",
      "D loss: 0.07322\n",
      "G loss: 5.015\n",
      "Iter: 4000\n",
      "D loss: 0.144\n",
      "G loss: 6.019\n",
      "Iter: 5000\n",
      "D loss: 0.2726\n",
      "G loss: 5.88\n",
      "Iter: 6000\n",
      "D loss: 0.2928\n",
      "G loss: 3.497\n",
      "Iter: 7000\n",
      "D loss: 0.4343\n",
      "G loss: 3.417\n",
      "Iter: 8000\n",
      "D loss: 0.5618\n",
      "G loss: 3.666\n",
      "Iter: 9000\n",
      "D loss: 0.4869\n",
      "G loss: 3.179\n",
      "Iter: 10000\n",
      "D loss: 0.5147\n",
      "G loss: 3.195\n",
      "Iter: 11000\n",
      "D loss: 0.5867\n",
      "G loss: 2.74\n",
      "Iter: 12000\n",
      "D loss: 0.6305\n",
      "G loss: 2.567\n",
      "Iter: 13000\n",
      "D loss: 0.7131\n",
      "G loss: 2.733\n",
      "Iter: 14000\n",
      "D loss: 0.7291\n",
      "G loss: 2.065\n",
      "Iter: 15000\n",
      "D loss: 0.5009\n",
      "G loss: 2.289\n",
      "Iter: 16000\n",
      "D loss: 0.7098\n",
      "G loss: 2.288\n",
      "Iter: 17000\n",
      "D loss: 0.6796\n",
      "G loss: 2.185\n",
      "Iter: 18000\n",
      "D loss: 0.7165\n",
      "G loss: 2.093\n",
      "Iter: 19000\n",
      "D loss: 0.7554\n",
      "G loss: 2.03\n",
      "Iter: 20000\n",
      "D loss: 0.7911\n",
      "G loss: 1.882\n",
      "Iter: 21000\n",
      "D loss: 0.7152\n",
      "G loss: 1.616\n",
      "Iter: 22000\n",
      "D loss: 0.7818\n",
      "G loss: 2.18\n",
      "Iter: 23000\n",
      "D loss: 0.7586\n",
      "G loss: 2.374\n",
      "Iter: 24000\n",
      "D loss: 0.6662\n",
      "G loss: 1.893\n",
      "Iter: 25000\n",
      "D loss: 0.7004\n",
      "G loss: 1.998\n",
      "Iter: 26000\n",
      "D loss: 0.7071\n",
      "G loss: 1.676\n",
      "Iter: 27000\n",
      "D loss: 0.6524\n",
      "G loss: 1.873\n",
      "Iter: 28000\n",
      "D loss: 0.6891\n",
      "G loss: 2.031\n",
      "Iter: 29000\n",
      "D loss: 0.6586\n",
      "G loss: 2.146\n",
      "Iter: 30000\n",
      "D loss: 0.7661\n",
      "G loss: 2.27\n",
      "Iter: 31000\n",
      "D loss: 0.6668\n",
      "G loss: 2.2\n",
      "Iter: 32000\n",
      "D loss: 0.5971\n",
      "G loss: 2.487\n",
      "Iter: 33000\n",
      "D loss: 0.7754\n",
      "G loss: 2.61\n",
      "Iter: 34000\n",
      "D loss: 0.5885\n",
      "G loss: 2.394\n",
      "Iter: 35000\n",
      "D loss: 0.6454\n",
      "G loss: 2.422\n",
      "Iter: 36000\n",
      "D loss: 0.5614\n",
      "G loss: 2.472\n",
      "Iter: 37000\n",
      "D loss: 0.6788\n",
      "G loss: 2.286\n",
      "Iter: 38000\n",
      "D loss: 0.5887\n",
      "G loss: 2.66\n",
      "Iter: 39000\n",
      "D loss: 0.5858\n",
      "G loss: 2.192\n",
      "Iter: 40000\n",
      "D loss: 0.6296\n",
      "G loss: 2.268\n",
      "Iter: 41000\n",
      "D loss: 0.7169\n",
      "G loss: 2.126\n",
      "Iter: 42000\n",
      "D loss: 0.4622\n",
      "G loss: 2.787\n",
      "Iter: 43000\n",
      "D loss: 0.6836\n",
      "G loss: 2.521\n",
      "Iter: 44000\n",
      "D loss: 0.7559\n",
      "G loss: 2.045\n",
      "Iter: 45000\n",
      "D loss: 0.6715\n",
      "G loss: 2.133\n",
      "Iter: 46000\n",
      "D loss: 0.5894\n",
      "G loss: 2.491\n",
      "Iter: 47000\n",
      "D loss: 0.6751\n",
      "G loss: 2.134\n",
      "Iter: 48000\n",
      "D loss: 0.5348\n",
      "G loss: 2.525\n",
      "Iter: 49000\n",
      "D loss: 0.7145\n",
      "G loss: 2.469\n",
      "Iter: 50000\n",
      "D loss: 0.7613\n",
      "G loss: 2.349\n",
      "Iter: 51000\n",
      "D loss: 0.5329\n",
      "G loss: 2.354\n",
      "Iter: 52000\n",
      "D loss: 0.5537\n",
      "G loss: 2.476\n",
      "Iter: 53000\n",
      "D loss: 0.5795\n",
      "G loss: 2.119\n",
      "Iter: 54000\n",
      "D loss: 0.6286\n",
      "G loss: 2.384\n",
      "Iter: 55000\n",
      "D loss: 0.6179\n",
      "G loss: 2.017\n",
      "Iter: 56000\n",
      "D loss: 0.6516\n",
      "G loss: 2.256\n",
      "Iter: 57000\n",
      "D loss: 0.6025\n",
      "G loss: 2.239\n",
      "Iter: 58000\n",
      "D loss: 0.6795\n",
      "G loss: 2.036\n",
      "Iter: 59000\n",
      "D loss: 0.6221\n",
      "G loss: 2.36\n",
      "Iter: 60000\n",
      "D loss: 0.6028\n",
      "G loss: 2.455\n",
      "Iter: 61000\n",
      "D loss: 0.6179\n",
      "G loss: 2.488\n",
      "Iter: 62000\n",
      "D loss: 0.4775\n",
      "G loss: 2.253\n",
      "Iter: 63000\n",
      "D loss: 0.6053\n",
      "G loss: 2.396\n",
      "Iter: 64000\n",
      "D loss: 0.5802\n",
      "G loss: 2.178\n",
      "Iter: 65000\n",
      "D loss: 0.6096\n",
      "G loss: 2.133\n",
      "Iter: 66000\n",
      "D loss: 0.754\n",
      "G loss: 2.435\n",
      "Iter: 67000\n",
      "D loss: 0.7304\n",
      "G loss: 2.117\n",
      "Iter: 68000\n",
      "D loss: 0.5612\n",
      "G loss: 2.426\n",
      "Iter: 69000\n",
      "D loss: 0.5634\n",
      "G loss: 2.276\n",
      "Iter: 70000\n",
      "D loss: 0.5489\n",
      "G loss: 2.255\n",
      "Iter: 71000\n",
      "D loss: 0.647\n",
      "G loss: 2.101\n",
      "Iter: 72000\n",
      "D loss: 0.6435\n",
      "G loss: 2.211\n",
      "Iter: 73000\n",
      "D loss: 0.5682\n",
      "G loss: 2.35\n",
      "Iter: 74000\n",
      "D loss: 0.4913\n",
      "G loss: 2.323\n",
      "Iter: 75000\n",
      "D loss: 0.5707\n",
      "G loss: 2.658\n",
      "Iter: 76000\n",
      "D loss: 0.5485\n",
      "G loss: 2.353\n",
      "Iter: 77000\n",
      "D loss: 0.5832\n",
      "G loss: 2.171\n",
      "Iter: 78000\n",
      "D loss: 0.5809\n",
      "G loss: 2.37\n",
      "Iter: 79000\n",
      "D loss: 0.5486\n",
      "G loss: 2.334\n",
      "Iter: 80000\n",
      "D loss: 0.5165\n",
      "G loss: 2.155\n",
      "Iter: 81000\n",
      "D loss: 0.5631\n",
      "G loss: 2.341\n",
      "Iter: 82000\n",
      "D loss: 0.5813\n",
      "G loss: 2.415\n",
      "Iter: 83000\n",
      "D loss: 0.6398\n",
      "G loss: 2.189\n",
      "Iter: 84000\n",
      "D loss: 0.5226\n",
      "G loss: 2.376\n",
      "Iter: 85000\n",
      "D loss: 0.7\n",
      "G loss: 2.193\n",
      "Iter: 86000\n",
      "D loss: 0.5279\n",
      "G loss: 2.508\n",
      "Iter: 87000\n",
      "D loss: 0.7671\n",
      "G loss: 2.609\n",
      "Iter: 88000\n",
      "D loss: 0.5461\n",
      "G loss: 2.119\n",
      "Iter: 89000\n",
      "D loss: 0.5005\n",
      "G loss: 2.37\n",
      "Iter: 90000\n",
      "D loss: 0.6123\n",
      "G loss: 2.17\n",
      "Iter: 91000\n",
      "D loss: 0.5155\n",
      "G loss: 2.246\n",
      "Iter: 92000\n",
      "D loss: 0.5144\n",
      "G loss: 2.212\n",
      "Iter: 93000\n",
      "D loss: 0.5832\n",
      "G loss: 2.264\n",
      "Iter: 94000\n",
      "D loss: 0.5828\n",
      "G loss: 2.6\n",
      "Iter: 95000\n",
      "D loss: 0.6221\n",
      "G loss: 2.19\n",
      "Iter: 96000\n",
      "D loss: 0.5092\n",
      "G loss: 2.158\n",
      "Iter: 97000\n",
      "D loss: 0.4523\n",
      "G loss: 2.676\n",
      "Iter: 98000\n",
      "D loss: 0.4953\n",
      "G loss: 2.45\n",
      "Iter: 99000\n",
      "D loss: 0.6876\n",
      "G loss: 2.264\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "samples_dict = {}\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100000):\n",
    "        if i % 1000 == 0:\n",
    "            n_samples = 16\n",
    "            samples = sess.run(G_sample, feed_dict={Z: sample_Z(n_samples, Z_dim)})\n",
    "            samples_dict[i] = samples\n",
    "        \n",
    "        X_mb, _ = mnist.train.next_batch(batch_size)\n",
    "        _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(batch_size, Z_dim)})\n",
    "        _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(batch_size, Z_dim)})\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print \"Iter: {}\".format(i)\n",
    "            print \"D loss: {:.4}\".format(D_loss_curr)\n",
    "            print \"G loss: {:.4}\".format(G_loss_curr)\n",
    "            \n",
    "            saver.save(sess, 'save/GAN/GAN', global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11c8fd7d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD0CAYAAACo2tvDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c8aa050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(samples_dict[99000][5,:].reshape((28,28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x117c81890>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD0CAYAAACo2tvDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naNtfAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116eb9950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_mb[0,:].reshape((28,28)), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
